{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-02-04T16:11:20.728159Z","iopub.status.busy":"2024-02-04T16:11:20.727126Z","iopub.status.idle":"2024-02-04T16:12:49.447024Z","shell.execute_reply":"2024-02-04T16:12:49.445875Z","shell.execute_reply.started":"2024-02-04T16:11:20.728126Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting open_clip_torch\n","  Downloading open_clip_torch-2.24.0-py3-none-any.whl.metadata (30 kB)\n","Collecting sentence-transformers\n","  Downloading sentence_transformers-2.3.1-py3-none-any.whl.metadata (11 kB)\n","Collecting openai-clip\n","  Downloading openai-clip-1.0.1.tar.gz (1.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: torch>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (2.1.2)\n","Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (0.16.2)\n","Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (2023.12.25)\n","Collecting ftfy (from open_clip_torch)\n","  Downloading ftfy-6.1.3-py3-none-any.whl.metadata (6.2 kB)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (4.66.1)\n","Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (0.20.3)\n","Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (0.1.99)\n","Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (3.20.3)\n","Requirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (0.9.12)\n","Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.37.0)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.24.4)\n","Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\n","Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\n","Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (3.2.4)\n","Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open_clip_torch) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open_clip_torch) (2023.12.2)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open_clip_torch) (2.31.0)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open_clip_torch) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open_clip_torch) (4.9.0)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open_clip_torch) (21.3)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (3.1.2)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n","Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /opt/conda/lib/python3.10/site-packages (from ftfy->open_clip_torch) (0.2.13)\n","Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.16.0)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->open_clip_torch) (3.1.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9.0->open_clip_torch) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip_torch) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip_torch) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip_torch) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip_torch) (2023.11.17)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9.0->open_clip_torch) (1.3.0)\n","Downloading open_clip_torch-2.24.0-py3-none-any.whl (1.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sentence_transformers-2.3.1-py3-none-any.whl (132 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: openai-clip\n","  Building wheel for openai-clip (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for openai-clip: filename=openai_clip-1.0.1-py3-none-any.whl size=1368605 sha256=e5e13b5785a27911fb8193e86998a486da31e4e9c00358bf3adaea29f9b72e39\n","  Stored in directory: /root/.cache/pip/wheels/08/77/8e/8d2f862df6bf7fb4e2007062d2cbaeae49862ec7b56d041229\n","Successfully built openai-clip\n","Installing collected packages: ftfy, openai-clip, sentence-transformers, open_clip_torch\n","Successfully installed ftfy-6.1.3 open_clip_torch-2.24.0 openai-clip-1.0.1 sentence-transformers-2.3.1\n","Collecting git+https://github.com/huggingface/transformers\n","  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-i07tzpzl\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-i07tzpzl\n","  Resolved https://github.com/huggingface/transformers to commit 3d2900e829ab16757632f9dde891f1947cfc4be0\n","  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n","\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.0.dev0) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.0.dev0) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.0.dev0) (1.24.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.0.dev0) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.0.dev0) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.0.dev0) (2023.12.25)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.0.dev0) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.0.dev0) (0.15.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.0.dev0) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.0.dev0) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.0.dev0) (2023.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.0.dev0) (4.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.38.0.dev0) (3.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.0.dev0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.0.dev0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.0.dev0) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.0.dev0) (2023.11.17)\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for transformers: filename=transformers-4.38.0.dev0-py3-none-any.whl size=8452748 sha256=1cb447175b62bc023503b27e3d487dd2ce070a783928561be0223010194f2f14\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-xzi1wqa2/wheels/c0/14/d6/6c9a5582d2ac191ec0a483be151a4495fe1eb2a6706ca49f1b\n","Successfully built transformers\n","Installing collected packages: transformers\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.37.0\n","    Uninstalling transformers-4.37.0:\n","      Successfully uninstalled transformers-4.37.0\n","Successfully installed transformers-4.38.0.dev0\n","Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.20.3)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2023.12.2)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.66.1)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.9.0)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub) (3.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2023.11.17)\n","Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\n","Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.16.2)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2023.12.2)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.24.4)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2023.11.17)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"]}],"source":["!pip install open_clip_torch sentence-transformers openai-clip\n","!pip install git+https://github.com/huggingface/transformers\n","!pip install huggingface_hub\n","!pip install torch torchvision"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T16:12:49.449553Z","iopub.status.busy":"2024-02-04T16:12:49.449268Z","iopub.status.idle":"2024-02-04T16:12:59.060528Z","shell.execute_reply":"2024-02-04T16:12:59.059534Z","shell.execute_reply.started":"2024-02-04T16:12:49.449523Z"},"trusted":true},"outputs":[],"source":["import torch\n","import open_clip\n","import glob\n","from IPython.display import display\n","from IPython.display import Image as IPImage\n","import os\n","from tqdm.autonotebook import tqdm\n","import numpy as np\n","import re\n","import pandas as pd\n","from concurrent.futures import ThreadPoolExecutor\n","from sentence_transformers import util\n","from tqdm import tqdm\n","from PIL import Image, ImageOps\n","from collections import Counter\n","from numpy.linalg import norm\n","from torchvision import transforms\n","import matplotlib.pyplot as plt\n","from torchvision.datasets import ImageFolder\n","from transformers import (CLIPProcessor, \n","                          CLIPModel,AutoModel, \n","                          TrainingArguments)\n","import clip\n","import torch.nn as nn"]},{"cell_type":"markdown","metadata":{},"source":["- Setting"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T16:52:33.682520Z","iopub.status.busy":"2024-02-04T16:52:33.681586Z","iopub.status.idle":"2024-02-04T16:52:33.695598Z","shell.execute_reply":"2024-02-04T16:52:33.694797Z","shell.execute_reply.started":"2024-02-04T16:52:33.682482Z"},"trusted":true},"outputs":[],"source":["src_dir = '/kaggle/input/image-search/test/images'\n","query_dir = '/kaggle/input/image-search/queries/queries'\n","submission = pd.read_csv('/kaggle/input/image-search/sample_submission.csv')\n","submission['dot_class'] = 22\n","submission['cosine_class'] = 22\n","submission['euclidean_class'] = 22"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T16:12:59.084431Z","iopub.status.busy":"2024-02-04T16:12:59.084157Z","iopub.status.idle":"2024-02-04T16:12:59.088890Z","shell.execute_reply":"2024-02-04T16:12:59.087927Z","shell.execute_reply.started":"2024-02-04T16:12:59.084407Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T16:12:59.091567Z","iopub.status.busy":"2024-02-04T16:12:59.091230Z","iopub.status.idle":"2024-02-04T16:12:59.109670Z","shell.execute_reply":"2024-02-04T16:12:59.108806Z","shell.execute_reply.started":"2024-02-04T16:12:59.091537Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[('RN50', 'openai'),\n"," ('RN50', 'yfcc15m'),\n"," ('RN50', 'cc12m'),\n"," ('RN50-quickgelu', 'openai'),\n"," ('RN50-quickgelu', 'yfcc15m'),\n"," ('RN50-quickgelu', 'cc12m'),\n"," ('RN101', 'openai'),\n"," ('RN101', 'yfcc15m'),\n"," ('RN101-quickgelu', 'openai'),\n"," ('RN101-quickgelu', 'yfcc15m'),\n"," ('RN50x4', 'openai'),\n"," ('RN50x16', 'openai'),\n"," ('RN50x64', 'openai'),\n"," ('ViT-B-32', 'openai'),\n"," ('ViT-B-32', 'laion400m_e31'),\n"," ('ViT-B-32', 'laion400m_e32'),\n"," ('ViT-B-32', 'laion2b_e16'),\n"," ('ViT-B-32', 'laion2b_s34b_b79k'),\n"," ('ViT-B-32', 'datacomp_xl_s13b_b90k'),\n"," ('ViT-B-32', 'datacomp_m_s128m_b4k'),\n"," ('ViT-B-32', 'commonpool_m_clip_s128m_b4k'),\n"," ('ViT-B-32', 'commonpool_m_laion_s128m_b4k'),\n"," ('ViT-B-32', 'commonpool_m_image_s128m_b4k'),\n"," ('ViT-B-32', 'commonpool_m_text_s128m_b4k'),\n"," ('ViT-B-32', 'commonpool_m_basic_s128m_b4k'),\n"," ('ViT-B-32', 'commonpool_m_s128m_b4k'),\n"," ('ViT-B-32', 'datacomp_s_s13m_b4k'),\n"," ('ViT-B-32', 'commonpool_s_clip_s13m_b4k'),\n"," ('ViT-B-32', 'commonpool_s_laion_s13m_b4k'),\n"," ('ViT-B-32', 'commonpool_s_image_s13m_b4k'),\n"," ('ViT-B-32', 'commonpool_s_text_s13m_b4k'),\n"," ('ViT-B-32', 'commonpool_s_basic_s13m_b4k'),\n"," ('ViT-B-32', 'commonpool_s_s13m_b4k'),\n"," ('ViT-B-32-256', 'datacomp_s34b_b86k'),\n"," ('ViT-B-32-quickgelu', 'openai'),\n"," ('ViT-B-32-quickgelu', 'laion400m_e31'),\n"," ('ViT-B-32-quickgelu', 'laion400m_e32'),\n"," ('ViT-B-32-quickgelu', 'metaclip_400m'),\n"," ('ViT-B-32-quickgelu', 'metaclip_fullcc'),\n"," ('ViT-B-16', 'openai'),\n"," ('ViT-B-16', 'laion400m_e31'),\n"," ('ViT-B-16', 'laion400m_e32'),\n"," ('ViT-B-16', 'laion2b_s34b_b88k'),\n"," ('ViT-B-16', 'datacomp_xl_s13b_b90k'),\n"," ('ViT-B-16', 'datacomp_l_s1b_b8k'),\n"," ('ViT-B-16', 'commonpool_l_clip_s1b_b8k'),\n"," ('ViT-B-16', 'commonpool_l_laion_s1b_b8k'),\n"," ('ViT-B-16', 'commonpool_l_image_s1b_b8k'),\n"," ('ViT-B-16', 'commonpool_l_text_s1b_b8k'),\n"," ('ViT-B-16', 'commonpool_l_basic_s1b_b8k'),\n"," ('ViT-B-16', 'commonpool_l_s1b_b8k'),\n"," ('ViT-B-16', 'dfn2b'),\n"," ('ViT-B-16-quickgelu', 'metaclip_400m'),\n"," ('ViT-B-16-quickgelu', 'metaclip_fullcc'),\n"," ('ViT-B-16-plus-240', 'laion400m_e31'),\n"," ('ViT-B-16-plus-240', 'laion400m_e32'),\n"," ('ViT-L-14', 'openai'),\n"," ('ViT-L-14', 'laion400m_e31'),\n"," ('ViT-L-14', 'laion400m_e32'),\n"," ('ViT-L-14', 'laion2b_s32b_b82k'),\n"," ('ViT-L-14', 'datacomp_xl_s13b_b90k'),\n"," ('ViT-L-14', 'commonpool_xl_clip_s13b_b90k'),\n"," ('ViT-L-14', 'commonpool_xl_laion_s13b_b90k'),\n"," ('ViT-L-14', 'commonpool_xl_s13b_b90k'),\n"," ('ViT-L-14-quickgelu', 'metaclip_400m'),\n"," ('ViT-L-14-quickgelu', 'metaclip_fullcc'),\n"," ('ViT-L-14-quickgelu', 'dfn2b'),\n"," ('ViT-L-14-336', 'openai'),\n"," ('ViT-H-14', 'laion2b_s32b_b79k'),\n"," ('ViT-H-14-quickgelu', 'metaclip_fullcc'),\n"," ('ViT-H-14-quickgelu', 'dfn5b'),\n"," ('ViT-H-14-378-quickgelu', 'dfn5b'),\n"," ('ViT-g-14', 'laion2b_s12b_b42k'),\n"," ('ViT-g-14', 'laion2b_s34b_b88k'),\n"," ('ViT-bigG-14', 'laion2b_s39b_b160k'),\n"," ('roberta-ViT-B-32', 'laion2b_s12b_b32k'),\n"," ('xlm-roberta-base-ViT-B-32', 'laion5b_s13b_b90k'),\n"," ('xlm-roberta-large-ViT-H-14', 'frozen_laion5b_s13b_b90k'),\n"," ('convnext_base', 'laion400m_s13b_b51k'),\n"," ('convnext_base_w', 'laion2b_s13b_b82k'),\n"," ('convnext_base_w', 'laion2b_s13b_b82k_augreg'),\n"," ('convnext_base_w', 'laion_aesthetic_s13b_b82k'),\n"," ('convnext_base_w_320', 'laion_aesthetic_s13b_b82k'),\n"," ('convnext_base_w_320', 'laion_aesthetic_s13b_b82k_augreg'),\n"," ('convnext_large_d', 'laion2b_s26b_b102k_augreg'),\n"," ('convnext_large_d_320', 'laion2b_s29b_b131k_ft'),\n"," ('convnext_large_d_320', 'laion2b_s29b_b131k_ft_soup'),\n"," ('convnext_xxlarge', 'laion2b_s34b_b82k_augreg'),\n"," ('convnext_xxlarge', 'laion2b_s34b_b82k_augreg_rewind'),\n"," ('convnext_xxlarge', 'laion2b_s34b_b82k_augreg_soup'),\n"," ('coca_ViT-B-32', 'laion2b_s13b_b90k'),\n"," ('coca_ViT-B-32', 'mscoco_finetuned_laion2b_s13b_b90k'),\n"," ('coca_ViT-L-14', 'laion2b_s13b_b90k'),\n"," ('coca_ViT-L-14', 'mscoco_finetuned_laion2b_s13b_b90k'),\n"," ('EVA01-g-14', 'laion400m_s11b_b41k'),\n"," ('EVA01-g-14-plus', 'merged2b_s11b_b114k'),\n"," ('EVA02-B-16', 'merged2b_s8b_b131k'),\n"," ('EVA02-L-14', 'merged2b_s4b_b131k'),\n"," ('EVA02-L-14-336', 'merged2b_s6b_b61k'),\n"," ('EVA02-E-14', 'laion2b_s4b_b115k'),\n"," ('EVA02-E-14-plus', 'laion2b_s9b_b144k'),\n"," ('ViT-B-16-SigLIP', 'webli'),\n"," ('ViT-B-16-SigLIP-256', 'webli'),\n"," ('ViT-B-16-SigLIP-i18n-256', 'webli'),\n"," ('ViT-B-16-SigLIP-384', 'webli'),\n"," ('ViT-B-16-SigLIP-512', 'webli'),\n"," ('ViT-L-16-SigLIP-256', 'webli'),\n"," ('ViT-L-16-SigLIP-384', 'webli'),\n"," ('ViT-SO400M-14-SigLIP', 'webli'),\n"," ('ViT-SO400M-14-SigLIP-384', 'webli'),\n"," ('ViT-L-14-CLIPA', 'datacomp1b'),\n"," ('ViT-L-14-CLIPA-336', 'datacomp1b'),\n"," ('ViT-H-14-CLIPA', 'datacomp1b'),\n"," ('ViT-H-14-CLIPA-336', 'laion2b'),\n"," ('ViT-H-14-CLIPA-336', 'datacomp1b'),\n"," ('ViT-bigG-14-CLIPA', 'datacomp1b'),\n"," ('ViT-bigG-14-CLIPA-336', 'datacomp1b'),\n"," ('nllb-clip-base', 'v1'),\n"," ('nllb-clip-large', 'v1'),\n"," ('nllb-clip-base-siglip', 'v1'),\n"," ('nllb-clip-large-siglip', 'v1')]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["open_clip.list_pretrained()"]},{"cell_type":"markdown","metadata":{},"source":["- Define model"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T16:12:59.110981Z","iopub.status.busy":"2024-02-04T16:12:59.110752Z","iopub.status.idle":"2024-02-04T16:17:41.496625Z","shell.execute_reply":"2024-02-04T16:17:41.495844Z","shell.execute_reply.started":"2024-02-04T16:12:59.110960Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1667dcb2067d4f83a034556a5a982749","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/4.88k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b56d45e03a8349f5b12c313e1eb400bf","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin.index.json:   0%|          | 0.00/120k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d5b00929fd92449f882167f8af3a53bb","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"848a2735096e4813bde022e50266265b","version_major":2,"version_minor":0},"text/plain":["pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.99G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af4d87f567f44edf8fd45fc1fb5414a4","version_major":2,"version_minor":0},"text/plain":["pytorch_model-00002-of-00002.bin:   0%|          | 0.00/169M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"acda92427d0346e3b6fd2fe9fda895ed","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n","2024-02-04 16:17:28.955949: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-02-04 16:17:28.956056: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-02-04 16:17:29.071510: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a26a4f5d5fda4cc2898a57cb8ffc3553","version_major":2,"version_minor":0},"text/plain":["preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"45350e5b01a54829911838c7cf6e71ee","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/904 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d2e66860b585417cbf76d557ecf12d49","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/862k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"197030ba441c4bcda2e189e10a2c14b7","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e66c42eb0f6c49878a5d113657b93961","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/2.22M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cfd2f3596dea44df8229edd5b461e742","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["model = AutoModel.from_pretrained('laion/CLIP-ViT-bigG-14-laion2B-39B-b160k').cuda().eval()\n","processor = CLIPProcessor.from_pretrained('laion/CLIP-ViT-bigG-14-laion2B-39B-b160k')"]},{"cell_type":"markdown","metadata":{},"source":["- Querying"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T16:52:40.180309Z","iopub.status.busy":"2024-02-04T16:52:40.179488Z","iopub.status.idle":"2024-02-04T16:56:42.089053Z","shell.execute_reply":"2024-02-04T16:56:42.087899Z","shell.execute_reply.started":"2024-02-04T16:52:40.180277Z"},"trusted":true},"outputs":[],"source":["with torch.no_grad():\n","    query_images = []\n","    query_classes = []\n","    for file in os.listdir(query_dir):\n","        inputs = processor(images=[Image.open(os.path.join(query_dir, file)).convert('L')], return_tensors='pt').to('cuda')\n","        outputs = model.get_image_features(inputs.pixel_values).cpu()\n","        outputs = outputs / outputs.norm(p=2, dim=-1, keepdim=True)\n","        query_images.append(outputs)\n","        query_classes.append(int(file[:-4]))\n","    query_images = torch.cat(query_images)\n","    for idx, row in submission.iterrows():\n","        if not pd.isna(row['class']):\n","            continue\n","        inputs = processor(images=[Image.open(os.path.join(src_dir, row['img_file'])).convert('L')], return_tensors='pt').to('cuda')\n","        outputs = model.get_image_features(inputs.pixel_values).cpu()\n","        outputs = outputs / outputs.norm(p=2, dim=-1, keepdim=True)\n","        values = outputs @ query_images.T\n","        if values.softmax(1).max() > .055:\n","            submission.at[idx, 'dot_class'] = query_classes[values.argmax().numpy().tolist()]\n","        cosine = torch.cosine_similarity(outputs, query_images)\n","        if cosine.max() > 0.7:\n","            submission.at[idx, 'cosine_class'] = query_classes[cosine.argmax().numpy().tolist()]\n","        euclidean_distances = torch.cdist(outputs, query_images, p=2)\n","        min_distance, min_idx = euclidean_distances.min(dim=1)\n","        if min_distance.item() < 0.4:\n","            closest_class = query_classes[min_idx.item()]\n","            submission.at[idx, 'euclidean_class'] = closest_class"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T16:57:01.672110Z","iopub.status.busy":"2024-02-04T16:57:01.671351Z","iopub.status.idle":"2024-02-04T16:57:04.655610Z","shell.execute_reply":"2024-02-04T16:57:04.654611Z","shell.execute_reply.started":"2024-02-04T16:57:01.672074Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["                                   img_file voted_class\n","0  64ccfecf-e451-49a8-aa3f-acf2622a9a5c.jpg          22\n","1  c6df1385-382a-4428-b41e-f2d729b90c87.jpg          22\n","2  af30e9d0-da6e-42bd-814e-c70a0c16e554.jpg          22\n","3  3fc8998e-0324-426c-8233-6b76abc7e200.jpg          22\n","4  309d1085-0d11-4411-9555-b24cc8fcee02.jpg          22\n"]}],"source":["image_files = submission['img_file'].unique()\n","\n","voting_results = pd.DataFrame({'img_file': image_files, 'voted_class': None})\n","\n","\n","for idx, image_file in enumerate(image_files):\n","\n","    dot_vote = submission.loc[submission['img_file'] == image_file, 'dot_class'].mode().values[0]\n","    cosine_vote = submission.loc[submission['img_file'] == image_file, 'cosine_class'].mode().values[0]\n","    euclidean_vote = submission.loc[submission['img_file'] == image_file, 'euclidean_class'].mode().values[0]\n","\n","\n","    votes = [dot_vote, cosine_vote, euclidean_vote]\n","    voted_class = max(set(votes), key=votes.count)\n","\n","\n","    voting_results.loc[voting_results['img_file'] == image_file, 'voted_class'] = voted_class\n","\n","\n","final_results = voting_results[['img_file', 'voted_class']]\n","print(final_results.head())"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T16:57:08.430236Z","iopub.status.busy":"2024-02-04T16:57:08.429391Z","iopub.status.idle":"2024-02-04T16:57:08.438941Z","shell.execute_reply":"2024-02-04T16:57:08.438141Z","shell.execute_reply.started":"2024-02-04T16:57:08.430201Z"},"trusted":true},"outputs":[],"source":["final_results.to_csv('submission.csv',index=False)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7460879,"sourceId":67158,"sourceType":"competition"}],"dockerImageVersionId":30646,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
